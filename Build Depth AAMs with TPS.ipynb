{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Build Active Appearance Models (AAMs) with Thin plate spline (TPS) warps\n",
      "##### Version 0.1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1 Load data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "Use the **pickle** to load the data from a previously saved version."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mayavi.mlab as mlab\n",
      "import os.path\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import cPickle as pickle\n",
      "from scipy.io import loadmat\n",
      "from pybug.image import DepthImage\n",
      "from pybug.shape import PointCloud\n",
      "from pybug.landmark.labels import ibug_68_points, ibug_68_contour, ibug_68_trimesh, labeller\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists('/vol/atlas/pts08/basel-depthmaps-python.pkl'):\n",
      "    print \"Loading from previously pickled dataset\"\n",
      "    with open('/vol/atlas/pts08/basel-depthmaps-python.pkl', 'rb') as f:\n",
      "        data_dict = pickle.load(f)\n",
      "        images = data_dict['images']\n",
      "        depthmap_shapes = data_dict['depthmap_shapes']\n",
      "else:\n",
      "    # Load training images as landmarked images manually FROM MATLAB\n",
      "    basel_depthmaps = loadmat('/vol/data/basel-depthmaps.mat')\n",
      "    depthmaps = np.ascontiguousarray(basel_depthmaps['depthmaps'])\n",
      "    landmarks = np.ascontiguousarray(basel_depthmaps['landmarks'])\n",
      "    \n",
      "    # Infinities are no good\n",
      "    depthmaps[np.isinf(depthmaps)] = np.nan\n",
      "    \n",
      "    # For each depth channel\n",
      "    images = []\n",
      "    depthmap_shapes = []\n",
      "    N = depthmaps.shape[2]\n",
      "    \n",
      "    for i, (im, pc) in enumerate(zip(np.rollaxis(depthmaps, 2), np.rollaxis(landmarks, 2))):\n",
      "        sys.stdout.write('\\rProcessing Face {0}/{1}'.format(i + 1, N))\n",
      "        images.append(DepthImage(im[..., None]))\n",
      "        depthmap_shapes.append(PointCloud(pc[:, ::-1]))\n",
      "        sys.stdout.flush()\n",
      "    print \"\"\n",
      "    \n",
      "    [d.add_landmark_set('IBUG', {'all': s}) for d, s in zip(images, depthmap_shapes)]\n",
      "    print \"Adding landmarks\"\n",
      "    \n",
      "    # label landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "    labeller(images, 'IBUG', ibug_68_points)\n",
      "    labeller(images, 'IBUG', ibug_68_contour)\n",
      "    labeller(images, 'IBUG', ibug_68_trimesh)\n",
      "    print \"Landmarks Added\"\n",
      "\n",
      "    # Save out so that the results are cached\n",
      "    with open('/vol/atlas/pts08/basel-depthmaps-python.pkl', 'wb') as f:\n",
      "        pickle.dump({'images': images, 'depthmap_shapes': depthmap_shapes}, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = images[0]\n",
      "\n",
      "# visualize first image\n",
      "img.view_new(mode='height')\n",
      "img.view_new()\n",
      "img.landmarks['ibug_68_points'].view_new()\n",
      "img.landmarks['ibug_68_contour'].view_new()\n",
      "img.landmarks['ibug_68_trimesh'].view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have now loaded enough data to create a meaninful **Active Appearance Model (AAM)** from the LFPW database."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Build Reference Frame (RF)\n",
      "\n",
      "We start by centereing all shapes around the origin (0,0)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.shape import PointCloud\n",
      "\n",
      "points = [img.landmarks['IBUG'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]\n",
      "\n",
      "centralized_points = [p - np.mean(p, axis=0) for p in points]\n",
      "centralized_shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualy check that indeed they are now centered."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralized_shapes[0].view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Normalize the centered shapes up to a similarity transform by performing Procrustes Analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.rigid import GeneralizedProcrustesAnalysis\n",
      "\n",
      "gpa = GeneralizedProcrustesAnalysis(centralized_points)\n",
      "aligned_points = [p[-1].aligned_source for p in gpa.procrustes]\n",
      "aligned_shapes = [PointCloud(p) for p in aligned_points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to define the template frame, we will need a function that checks if a particular point is inside a given convex polygon. We define this function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the reference frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_points = np.mean(aligned_points, axis=0)\n",
      "margin = 3\n",
      "template_landmarks = PointCloud(mean_points - np.min(mean_points, axis=0) + margin)\n",
      "\n",
      "# the resolution of the template is typically related to the size of the mean shape\n",
      "scale = 1\n",
      "template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the template image\n",
      "template = DepthImage.blank(template_resolution)\n",
      "\n",
      "# Add the template landmarks and label them\n",
      "template.add_landmark_set('IBUG', {'all': template_landmarks})\n",
      "labeller([template], 'IBUG', ibug_68_contour)\n",
      "labeller([template], 'IBUG', ibug_68_trimesh)\n",
      "labeller([template], 'IBUG', ibug_68_points)\n",
      "\n",
      "# Constrain the mask to the area of the contour\n",
      "template.constrain_mask_to_landmarks(group='ibug_68_contour')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "template.landmarks['ibug_68_trimesh'].view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_template(points, label_func=ibug_68_contour, label='ibug_68_contour', margin=3, scale=1):\n",
      "    template_landmarks = PointCloud(points - np.min(points, axis=0) + margin)\n",
      "    template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)\n",
      "    template_data = np.zeros(template_resolution)\n",
      "\n",
      "    template = DepthImage(template_data[..., None])\n",
      "    template.add_landmark_set('IBUG', {'all': template_landmarks})\n",
      "    labeller([template], 'IBUG', ibug_68_contour)\n",
      "    \n",
      "    template.constrain_mask_to_landmarks(group=label)\n",
      "    \n",
      "    return template, template_landmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Warp the Images\n",
      "\n",
      "The next step consists of *warping* the original LFPW images onto the *reference frame* using the correspondances between their *landmarks* and the *texture coordinates* on the reference frame. We can either use **Piece Wise Affine ** (PWA) or **Thin Plate Spline ** (TPS) for this purpose. The differences between the two families of warps can be observed by visualizing the obtained warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.nonrigid.tps import TPS\n",
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.warp import scipy_warp\n",
      "from scipy.spatial import Delaunay\n",
      "\n",
      "trilist = template.landmarks['ibug_68_trimesh'].landmark_dict['tri'].trilist\n",
      "\n",
      "pwa = [TPS(template_landmarks.points, s.points) for s in shapes]\n",
      "warped_images = [scipy_warp(img, template, t.transform) for img, t in zip(images, pwa)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Build the Appearance Model\n",
      "The AAM's *appearance model* is typically build by applying **Principal Component Analysis** (PCA) to the previously warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "# this would perfectly work in rgb space provided that all original images had rgb color channels (which is not the \n",
      "# case for the LFPW training dataset)\n",
      "appearance_model = PCAModel(warped_images, n_components=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "appearance_parameters = [np.random.randn(appearance_model.n_components) for i in range(n_instances)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_axis = range(appearance_model.n_components)\n",
      "cumulative_variance = [np.sum(appearance_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "appearance_instances = [appearance_model.instance(appearance_parameters[i] * \n",
      "                        np.sqrt(appearance_model.explained_variance)) for i in range(n_instances)]\n",
      "\n",
      "plt.subplot(1,2,1)\n",
      "plt.plot(x_axis, cumulative_variance)\n",
      "plt.subplot(1,2,2)\n",
      "appearance_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Build the Shape Model\n",
      "Similarly, the shape model of the AAM is tipically build by applying PCA to the aligned shapes obtained from GPA. At this point, it is interesting to see the differences between the sets of original, centralized and aligned shapes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "\n",
      "shape_model = PCAModel(aligned_shapes, n_components=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "shape_parameters = [np.random.randn(shape_model.n_components) for i in range(n_instances)]\n",
      "\n",
      "x_axis = range(shape_model.n_components)\n",
      "cumulative_variance = [np.sum(shape_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "shape_instances = [shape_model.instance(shape_parameters[i] * np.sqrt(shape_model.explained_variance)) \n",
      "    for i in range(n_instances)]\n",
      "\n",
      "plt.subplot(1,2,1)\n",
      "plt.plot(x_axis, cumulative_variance)\n",
      "plt.subplot(1,2,2)\n",
      "shape_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Generate an AAM instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = np.random.randint(n_instances)\n",
      "\n",
      "shape_instance = shape_instances[i]\n",
      "\n",
      "# build a template for the chosen shape instance\n",
      "instance_template, instance_landmarks = build_template(shape_instance.points)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "instance = TPS(instance_landmarks.points, template_landmarks.points)\n",
      "model_instance = scipy_warp(appearance_instances[i], instance_template, instance.transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_instance.view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Save the AAM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/vol/data/basel_tps', 'wb') as f:\n",
      "    pickle.dump({'shape_model': shape_model, \n",
      "                 'appearance_model': appearance_model,\n",
      "                 'template': template,\n",
      "                 'template_landmarks': template_landmarks},\n",
      "                f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}