{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fit AAMs using the Project Out algorithm\n",
      "\n",
      "### 1. Load the data\n",
      "\n",
      "Use the **autoimporter** to automatically load the *annotated* test images of the *Labelled Faces Parts in the Wild (LFPW)* dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import loadmat\n",
      "from pybug.transform.affine import Translation\n",
      "from pybug.shape import PointCloud\n",
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import ibug_68_points, ibug_68_contour, ibug_68_trimesh, labeller\n",
      "\n",
      "images = auto_import('/vol/atlas/databases/frgc/spring2004/*.abs', max_images=1)\n",
      "images = [im.as_depth_image() for im in images]\n",
      "\n",
      "# Extract shape data. -1 because the annotation are 1 based\n",
      "translate = Translation(np.array([-1, -1]))\n",
      "points = [translate.apply(img.landmarks['PTS'].lms).points for img in images]\n",
      "shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use **pickle** to load a previously build *AAM*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "\n",
      "# load a previously buid AAM\n",
      "with open('/vol/data/frgc_spring2003_spherical_pwa', \"rb\") as f:\n",
      "    aam = cPickle.load(f)\n",
      "\n",
      "reference_frame = aam[\"template\"]\n",
      "appearance_model = aam[\"appearance_model\"]\n",
      "shape_model = aam[\"shape_model\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Fit\n",
      "\n",
      "Randomly select an image to fit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.ndimage.filters import median_filter\n",
      "from pybug.image import DepthImage\n",
      "\n",
      "# select a test image at random\n",
      "ind = 0\n",
      "original_image = images[ind]\n",
      "test_shape = shapes[ind]\n",
      "\n",
      "original_image.view_new(mode='mesh', normals=original_image.mesh.vertex_normals, mask_points=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cosine_normals import logmap_cosine\n",
      "from pybug.image import MaskedNDImage\n",
      "import copy\n",
      "\n",
      "normals = original_image.mesh.vertex_normals\n",
      "features = logmap_cosine(normals)\n",
      "new_im = MaskedNDImage.blank(im.shape, mask=im.mask, n_channels=4)\n",
      "new_im.update_from_vector(features.flatten())\n",
      "new_im.landmarks = im.landmarks\n",
      "\n",
      "test_image = new_im\n",
      "test_image.view_new(channel=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize ground truth landmarks and warped appearance for the selected test image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.warp import scipy_warp\n",
      "\n",
      "source = reference_frame.landmarks['IBUG']\n",
      "\n",
      "tps = PiecewiseAffineTransform(source.lms.points, test_shape.points)\n",
      "template = scipy_warp(test_image, reference_frame, tps)\n",
      "\n",
      "test_image.landmarks['ground_truth'] = test_shape\n",
      "test_image.landmarks['ground_truth'].view_new()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "template.landmarks['reference'] = source\n",
      "template.landmarks['reference'].view_new()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build Statistically Driven Transform using the AAM's shape model and Piece Wise Affine (PWA) warps: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.statisticallydriven import StatisticallyDrivenTransform\n",
      "from pybug.transform.affine import SimilarityTransform\n",
      "\n",
      "def pwa_constructor(src_landmarks, tgt_landmarks):\n",
      "    return PiecewiseAffineTransform(src_landmarks, tgt_landmarks)\n",
      "\n",
      "dummy_similarity_transform = SimilarityTransform.from_vector(np.array([0, 0, 0, 0]))\n",
      "global_transform = dummy_similarity_transform\n",
      "\n",
      "stat_driven_transform = StatisticallyDrivenTransform(shape_model, pwa_constructor,\n",
      "                                                     source=source.lms, \n",
      "                                                     global_transform=global_transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build three \"fitter\" objects using the three variations of the Project Out algorithm:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.lucaskanade.residual import LSIntensity\n",
      "from pybug.lucaskanade.appearance.alternating import (AlternatingForwardAdditive,\n",
      "                                                      AlternatingForwardCompositional,\n",
      "                                                      AlternatingInverseCompositional)\n",
      "# standard Least Squares Residual\n",
      "residual = LSIntensity()\n",
      "\n",
      "# forward additive\n",
      "fa = AlternatingForwardAdditive(appearance_model, residual, stat_driven_transform)\n",
      "# forwad compositional\n",
      "fc = AlternatingForwardCompositional(appearance_model, residual, stat_driven_transform)\n",
      "# inverse compositional\n",
      "ic = AlternatingInverseCompositional(appearance_model, residual, stat_driven_transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize the fitting procedure by perturbing the true scale and translation parameters of the manually annotated shape:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.affine import SimilarityTransform\n",
      "import numpy as np\n",
      "\n",
      "# estimate the true similarity transform\n",
      "similarity_transform = SimilarityTransform.estimate(shape_model.mean.points, \n",
      "                                                    test_shape.points)\n",
      "\n",
      "global_parameters = similarity_transform.as_vector()\n",
      "# kill rotation\n",
      "global_parameters[1] = 0\n",
      "# add random gaussian noise to the ground truth parameters\n",
      "global_parameters += 0.1 * np.random.randn(4) \n",
      "\n",
      "global_transform = SimilarityTransform.from_vector(global_parameters)\n",
      "\n",
      "aligned_test_points = global_transform.inverse.apply(test_shape.points)\n",
      "aligned_test_shape = PointCloud(aligned_test_points)\n",
      "weights = shape_model.project(aligned_test_shape)\n",
      "\n",
      "initial_parameters = np.concatenate([global_parameters, np.zeros_like(weights)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the correctness of the initialization:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_transform = stat_driven_transform.from_vector(initial_parameters)\n",
      "initial_warped_image = scipy_warp(test_image, template, initial_transform)\n",
      "\n",
      "original_image.mesh.texture.landmarks['initial'] = initial_transform.target\n",
      "original_image.mesh.texture.landmarks['initial'].view_new()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "initial_warped_image.landmarks['reference'] = source\n",
      "initial_warped_image.landmarks['reference'].view_new()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit the image using all three different methods:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimal_transform_1 = fa.align(test_image, initial_parameters, max_iters=50)\n",
      "optimal_transform_2 = fc.align(test_image, initial_parameters, max_iters=50)\n",
      "optimal_transform_3 = ic.align(test_image, initial_parameters, max_iters=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_appearance_1 = scipy_warp(test_image, template, optimal_transform_1)\n",
      "fitted_appearance_2 = scipy_warp(test_image, template, optimal_transform_2)\n",
      "fitted_appearance_3 = scipy_warp(test_image, template, optimal_transform_3)\n",
      "\n",
      "fitted_appearance_1.landmarks['reference'] = source\n",
      "fitted_appearance_1.landmarks['reference'].view_new()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "fitted_appearance_2.landmarks['reference'] = source\n",
      "fitted_appearance_2.landmarks['reference'].view_new()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "fitted_appearance_3.landmarks['reference'] = source\n",
      "fitted_appearance_3.landmarks['reference'].view_new()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_image.landmarks['initial'] = initial_transform.target\n",
      "test_image.landmarks['fa'] = optimal_transform_1.target\n",
      "test_image.landmarks['fc'] = optimal_transform_2.target\n",
      "test_image.landmarks['ic'] = optimal_transform_3.target\n",
      "\n",
      "test_image.landmarks.view()\n",
      "gcf().set_size_inches((10,10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}